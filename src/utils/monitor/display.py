import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import json
from datetime import datetime
import pandas as pd
from .evaluate import *
from .evaluate_llm import *

def display_constraints_eval_result(agent_data=None):
    #st.set_page_config(layout="wide")
    st.title("ğŸµ LLM ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì„œë¹„ìŠ¤ ì œì•½ ì¡°ê±´ ì¤€ìˆ˜ í‰ê°€")

    st.markdown("""
    ì´ ëŒ€ì‹œë³´ë“œëŠ” LLM ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì„œë¹„ìŠ¤ì˜ íŠ¹ì • ì œì•½ ì¡°ê±´ ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ì—ì´ì „íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ 'ì‚¬ìš©ì ì„ í˜¸ë„ ë¯¸ë°˜ì˜' ë° 'ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œ ê¸ˆì§€'ì™€ ê°™ì€
    í•µì‹¬ ì œì•½ ì¡°ê±´ì´ ì–¼ë§ˆë‚˜ ì˜ ì§€ì¼œì¡ŒëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """)

    st.markdown(
    """
    <style>
    div[data-testid="stMetricValue"] {
        font-size: 24px; /* ê°’(ìˆ«ì)ì˜ í°íŠ¸ í¬ê¸° */
    }
    div[data-testid="stMetricLabel"] > div {
        font-size: 14px; /* ë¼ë²¨(í…ìŠ¤íŠ¸)ì˜ í°íŠ¸ í¬ê¸° */
    }
    </style>
    """,
    unsafe_allow_html=True
    )
    if agent_data:
        st.header("1. ì—ì´ì „íŠ¸ ë°ì´í„° ìš”ì•½")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì‚¬ìš©ì ID", agent_data.get('user_id', 'N/A'))
        with col2:
            st.metric("ì±„íŒ… ì´ë¦„", agent_data.get('chat_name', 'N/A'))
        with col3:
            st.metric("ì´ ë©”ì‹œì§€ í„´ ìˆ˜", agent_data.get('num_chat_turn', 'N/A'))

        st.subheader("ì´ˆê¸° ì‚¬ìš©ì ìš”ì²­")
        initial_human_message = ""
        if agent_data and 'messages' in agent_data and len(agent_data['messages']) > 0:
            if agent_data['messages'][0].get('type') == 'human':
                initial_human_message = agent_data['messages'][0]['content']
        st.code(initial_human_message, language='text')

        st.header("2. ì œì•½ ì¡°ê±´ í‰ê°€ ê²°ê³¼")
        
        constraint_results = evaluate_constraints(agent_data)

        # í‰ê°€ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™”
        results_df = pd.DataFrame([constraint_results]).T
        results_df.columns = ['ì¤€ìˆ˜ ì—¬ë¶€']
        
        # ì‹œê°í™”ë¥¼ ìœ„í•œ ìƒ‰ìƒ ë§¤í•‘
        def get_status_color(value):
            if value is True:
                return ":green[âœ” ì¤€ìˆ˜]"
            elif value is False:
                return ":red[âœ– ìœ„ë°˜]"
            else:
                return ":orange[â“ ì •ë³´ ì—†ìŒ]"

        st.markdown("### ì£¼ìš” ì œì•½ ì¡°ê±´")
        st.table(results_df.map(get_status_color))

        st.markdown("### ìƒì„¸ í‰ê°€")
        st.write("ê° ì œì•½ ì¡°ê±´ì— ëŒ€í•œ ìƒì„¸ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.")
        
        st.subheader("ì‚¬ìš©ì ì„ í˜¸ë„ ë¯¸ë°˜ì˜ (user_preference_reflected)")
        if constraint_results['ì‚¬ìš©ì ì„ í˜¸ë„ ë¯¸ë°˜ì˜'] is True:
            st.success("âœ… **ì¤€ìˆ˜:** `user_preference_reflected` ê°’ì´ `False`ë¡œ ì„¤ì •ë˜ì–´ ì‚¬ìš©ì ê¸°ì¡´ ì„ í˜¸ë„ê°€ ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif constraint_results['ì‚¬ìš©ì ì„ í˜¸ë„ ë¯¸ë°˜ì˜'] is False:
            st.error("âŒ **ìœ„ë°˜:** `user_preference_reflected` ê°’ì´ `True`ë¡œ ì„¤ì •ë˜ì–´ ì‚¬ìš©ì ê¸°ì¡´ ì„ í˜¸ë„ê°€ ë°˜ì˜ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("â“ **ì •ë³´ ì—†ìŒ:** `user_preference_reflected` ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if constraint_results['ì´ˆê¸° ìš”ì²­: ì„ í˜¸ë„ ë¯¸ë°˜ì˜ ëª…ì‹œ']:
            st.info("â„¹ï¸ ì´ˆê¸° ì‚¬ìš©ì ìš”ì²­ì— 'Do not incorporate the user's existing preferences.' ë¬¸êµ¬ê°€ ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ì´ˆê¸° ì‚¬ìš©ì ìš”ì²­ì— 'Do not incorporate the user's existing preferences.' ë¬¸êµ¬ê°€ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        st.subheader("ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œ ê¸ˆì§€ (re_recommendation_allowed)")
        if constraint_results['ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œ ê¸ˆì§€'] is True:
            st.success("âœ… **ì¤€ìˆ˜:** `re_recommendation_allowed` ê°’ì´ `False`ë¡œ ì„¤ì •ë˜ì–´ ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œì´ í—ˆìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif constraint_results['ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œ ê¸ˆì§€'] is False:
            st.error("âŒ **ìœ„ë°˜:** `re_recommendation_allowed` ê°’ì´ `True`ë¡œ ì„¤ì •ë˜ì–´ ì´ì „ ì¶”ì²œê³¡ ì¬ì¶”ì²œì´ í—ˆìš©ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("â“ **ì •ë³´ ì—†ìŒ:** `re_recommendation_allowed` ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        if constraint_results['ì´ˆê¸° ìš”ì²­: ì¬ì¶”ì²œ ê¸ˆì§€ ëª…ì‹œ']:
            st.info("â„¹ï¸ ì´ˆê¸° ì‚¬ìš©ì ìš”ì²­ì— 'Do NOT allow re-recommendation of previously recommended songs.' ë¬¸êµ¬ê°€ ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ì´ˆê¸° ì‚¬ìš©ì ìš”ì²­ì— 'Do NOT allow re-recommendation of previously recommended songs.' ë¬¸êµ¬ê°€ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        st.subheader("ìµœì¢… ì¶”ì²œ ê²°ê³¼ ë¶„ì„")
        if constraint_results['ìµœì¢… ì¶”ì²œ ì™„ë£Œ ì—¬ë¶€']:
            st.success(f"âœ… ìµœì¢… ì¶”ì²œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ì²œëœ ê³¡ ìˆ˜: {constraint_results['ì¶”ì²œëœ ê³¡ ìˆ˜']}ê³¡")
            if constraint_results['ì¶”ì²œ ë©”ì‹œì§€: ì´ì „ ì¶”ì²œ ë°©ì§€ ë¬¸êµ¬']:
                st.info("â„¹ï¸ ìµœì¢… ì¶”ì²œ ë©”ì‹œì§€ì— 'ì´ì „ì— ì¶”ì²œí•˜ì§€ ì•Šì•˜ë˜ ê³¡ë“¤ ì¤‘ì—ì„œ'ë¼ëŠ” ë¬¸êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ìµœì¢… ì¶”ì²œ ë©”ì‹œì§€ì— 'ì´ì „ì— ì¶”ì²œí•˜ì§€ ì•Šì•˜ë˜ ê³¡ë“¤ ì¤‘ì—ì„œ'ë¼ëŠ” ëª…ì‹œì ì¸ ë¬¸êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ ìµœì¢… ì¶”ì²œì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ `RECOMMENDATION_COMPLETE` ë§ˆì»¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.header("3. ì›ë³¸ ì—ì´ì „íŠ¸ ë°ì´í„°")
        st.json(agent_data) # ì›ë³¸ JSON ë°ì´í„° í‘œì‹œ

    else:
        st.warning("ì—ì´ì „íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì½”ë“œì˜ `AGENT_DATA_STR` ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


def display_llm_performance(agent_data=None):
    #st.set_page_config(layout="wide")
    st.title("ğŸ“Š LLM ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì„œë¹„ìŠ¤ ì„±ëŠ¥ í‰ê°€: íš¨ìœ¨ì„±, ì•ˆì •ì„±, ë ˆì´í„´ì‹œ")

    st.markdown("""
    ì´ ëŒ€ì‹œë³´ë“œëŠ” LLM ê¸°ë°˜ ìŒì•… ì¶”ì²œ ì„œë¹„ìŠ¤ì˜ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œì¸ íš¨ìœ¨ì„± (í† í° ì‚¬ìš©ëŸ‰),
    ì•ˆì •ì„± (ì˜¤ë¥˜ ë°œìƒ ì—¬ë¶€), ê·¸ë¦¬ê³  ì‘ë‹µ ì†ë„ (ë ˆì´í„´ì‹œ)ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
    """)

    st.markdown(
    """
    <style>
    div[data-testid="stMetricValue"] {
        font-size: 24px; /* ê°’(ìˆ«ì)ì˜ í°íŠ¸ í¬ê¸° */
    }
    div[data-testid="stMetricLabel"] > div {
        font-size: 14px; /* ë¼ë²¨(í…ìŠ¤íŠ¸)ì˜ í°íŠ¸ í¬ê¸° */
    }
    </style>
    """,
    unsafe_allow_html=True
    )
    if agent_data and 'messages' in agent_data:
        df_metrics = extract_llm_metrics(agent_data)

        if not df_metrics.empty:
            st.header("1. ì£¼ìš” ì„±ëŠ¥ ìš”ì•½")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ LLM í˜¸ì¶œ ìˆ˜", len(df_metrics))
            with col2:
                st.metric("ì´ í”„ë¡¬í”„íŠ¸ í† í°", df_metrics['prompt_tokens'].sum())
            with col3:
                st.metric("ì´ ì™„ë£Œ í† í°", df_metrics['completion_tokens'].sum())
            with col4:
                st.metric("ì´ í† í°", df_metrics['total_tokens'].sum())

            col5, col6 = st.columns(2)
            with col5:
                st.metric("ì „ì²´ ì˜¤ë¥˜ ë°œìƒ ìˆ˜", df_metrics['error_count'].sum())
            with col6:
                st.metric("ëª¨ë¸ë³„ í‰ê·  í† í° ì‚¬ìš©ëŸ‰", f"{df_metrics.groupby('model_name')['total_tokens'].mean().round(2).to_dict()}", help="ëª¨ë¸ë³„ í‰ê·  í† í° ì‚¬ìš©ëŸ‰ì…ë‹ˆë‹¤.")

            st.header("2. í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„")
            st.markdown("---")
            st.subheader("ì—ì´ì „íŠ¸ë³„ í† í° ì‚¬ìš©ëŸ‰")
            
            # ì—ì´ì „íŠ¸ë³„ í† í° ì‚¬ìš©ëŸ‰ ë°” ì°¨íŠ¸
            fig_tokens_by_agent = px.bar(
                df_metrics.groupby('agent_name')[['prompt_tokens', 'completion_tokens', 'total_tokens']].sum().reset_index(),
                x='agent_name',
                y=['prompt_tokens', 'completion_tokens', 'total_tokens'],
                title='ì—ì´ì „íŠ¸ë³„ ì´ í† í° ì‚¬ìš©ëŸ‰',
                labels={'value': 'í† í° ìˆ˜', 'variable': 'í† í° ìœ í˜•', 'agent_name': 'ì—ì´ì „íŠ¸'},
                barmode='group'
            )
            st.plotly_chart(fig_tokens_by_agent, use_container_width=True)

            st.subheader("ê°œë³„ LLM í˜¸ì¶œë³„ í† í° ì‚¬ìš©ëŸ‰")
            st.dataframe(df_metrics[['agent_name', 'model_name', 'prompt_tokens', 'completion_tokens', 'total_tokens']].sort_values(by='total_tokens', ascending=False))

            st.header("3. ì‘ë‹µ ì†ë„ (ë ˆì´í„´ì‹œ) ë¶„ì„")
            st.markdown("---")
            st.warning("âš ï¸ **ì£¼ì˜:** í˜„ì¬ ë ˆì´í„´ì‹œ ê°’ì€ ë©”ì‹œì§€ í„´ì˜ ìˆœì„œë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”„ë¡ì‹œ ê°’ì´ë©°, ì‹¤ì œ API ì‘ë‹µ ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤. ì •í™•í•œ ë ˆì´í„´ì‹œ ì¸¡ì •ì„ ìœ„í•´ì„œëŠ” LLM í˜¸ì¶œ ì‹œì ê³¼ ì‘ë‹µ ì™„ë£Œ ì‹œì ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ê¸°ë¡í•´ì•¼ í•©ë‹ˆë‹¤.")
            
            st.subheader("LLM í˜¸ì¶œ ìˆœì„œë³„ ë ˆì´í„´ì‹œ (í”„ë¡ì‹œ)")
            fig_latency = px.line(
                df_metrics,
                x='message_id',
                y='latency_proxy',
                title='LLM í˜¸ì¶œ ìˆœì„œë³„ ë ˆì´í„´ì‹œ (í”„ë¡ì‹œ)',
                labels={'message_id': 'ë©”ì‹œì§€ ID', 'latency_proxy': 'ë ˆì´í„´ì‹œ (ìˆœì„œ)'},
                hover_data=['agent_name', 'model_name', 'total_tokens']
            )
            st.plotly_chart(fig_latency, use_container_width=True)

            st.subheader("ì—ì´ì „íŠ¸ë³„ í‰ê·  ë ˆì´í„´ì‹œ (í”„ë¡ì‹œ)")
            avg_latency_by_agent = df_metrics.groupby('agent_name')['latency_proxy'].mean().reset_index()
            fig_avg_latency = px.bar(
                avg_latency_by_agent,
                x='agent_name',
                y='latency_proxy',
                title='ì—ì´ì „íŠ¸ë³„ í‰ê·  ë ˆì´í„´ì‹œ (í”„ë¡ì‹œ)',
                labels={'latency_proxy': 'í‰ê·  ë ˆì´í„´ì‹œ (ìˆœì„œ)', 'agent_name': 'ì—ì´ì „íŠ¸'}
            )
            st.plotly_chart(fig_avg_latency, use_container_width=True)


            st.header("4. ì•ˆì •ì„± (ì˜¤ë¥˜) ë¶„ì„")
            st.markdown("---")
            
            # ì—ëŸ¬ ìœ í˜•ë³„ í†µê³„
            error_counts = pd.DataFrame({
                'ì˜¤ë¥˜ ìœ í˜•': ['ê±°ë¶€ ì˜¤ë¥˜ (Refusal)', 'ìœ íš¨í•˜ì§€ ì•Šì€ íˆ´ í˜¸ì¶œ (Invalid Tool Calls)'],
                'ë°œìƒ íšŸìˆ˜': [df_metrics['refusal_error'].sum(), df_metrics['invalid_tool_calls_error'].sum()]
            })
            st.table(error_counts)

            total_errors = df_metrics['error_count'].sum()
            if total_errors > 0:
                st.error(f"âŒ **ì´ {total_errors} ê±´ì˜ LLM ê´€ë ¨ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.**")
                st.subheader("ì˜¤ë¥˜ ë°œìƒ LLM í˜¸ì¶œ ìƒì„¸")
                st.dataframe(df_metrics[df_metrics['error_count'] > 0][['message_id', 'agent_name', 'model_name', 'refusal_error', 'invalid_tool_calls_error', 'content', 'additional_kwargs']])
            else:
                st.success("âœ… **ëª¨ë“  LLM í˜¸ì¶œì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìœ¼ë©°, ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")

            st.header("5. ì›ë³¸ ì—ì´ì „íŠ¸ ë°ì´í„° (LLM ì‘ë‹µ ë¶€ë¶„)")
            # ëª¨ë“  AI ë©”ì‹œì§€ì˜ ì›ë³¸ ë°ì´í„°ë¥¼ ë³´ì—¬ì¤Œ
            llm_responses = [
                msg for msg in agent_data.get('messages', []) if msg.get('type') == 'ai'
            ]
            if llm_responses:
                st.json(llm_responses)
            else:
                st.info("LLM ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        else:
            st.warning("ë¶„ì„í•  LLM í˜¸ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. `messages` í•„ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.warning("ì—ì´ì „íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ 'messages' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. ì½”ë“œì˜ `AGENT_DATA_STR` ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")



def display_llm_component_eval(agent_data=None):
    if agent_data:
        evaluations = get_llm_evaluations(agent_data)
        # --- LLM ì„œë¹„ìŠ¤ ì •ë³´ í‘œì‹œ ---
        st.header("âš™ï¸ LLM ì—ì´ì „íŠ¸ êµ¬ì„± ì •ë³´")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("LLM ì„œë¹„ìŠ¤ ìœ í˜•", evaluations['llm_service_type'])
            st.metric("Supervisor ëª¨ë¸", evaluations['supervisor_model'])
        with col2:
            st.metric("ê²€ìƒ‰ ë„êµ¬ ì´ë¦„", evaluations['search_tool_name'])
            st.metric("Subagent ëª¨ë¸", evaluations['subagent_model'])
        with col3:
            st.metric("ì„ë² ë”© ëª¨ë¸", evaluations['embedding_model'])
            st.metric("ì„ë² ë”© ìœ í˜•", evaluations['embedding_type'])

        st.markdown("---")

        # --- í‰ê°€ ì§€í‘œ ìš”ì•½ í‘œ ---
        st.header("ğŸ“ˆ LLM í‰ê°€ ì§€í‘œ ìš”ì•½")

        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œë¡œ í‘œì‹œ
        eval_df = pd.DataFrame({
            'ì§€í‘œ': [
                'ì›¹ ê²€ìƒ‰ ë§¥ë½ ê´€ë ¨ì„± ì ìˆ˜',
                'ì‘ë‹µ ê´€ë ¨ì„± ì ìˆ˜',
                'ì‘ë‹µ ê·¼ê±° ì ìˆ˜'
            ],
            'ì ìˆ˜': [
                evaluations['web_search_context_relevance_score'],
                evaluations['response_relevancy_score'],
                evaluations['mean_response_groundedness_score']
            ]
        })
        # ì ìˆ˜ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
        eval_df['ì ìˆ˜'] = eval_df['ì ìˆ˜'].map(lambda x: f"{x:.2f}")

        st.dataframe(eval_df, hide_index=True, use_container_width=True)

        st.markdown("---")

        # --- í‰ê°€ ì§€í‘œ ì‹œê°í™” ---
        st.header("ğŸ“Š ì„¸ë¶€ í‰ê°€ ì§€í‘œ ì‹œê°í™”")

        # í‰ê°€ ì§€í‘œë¥¼ ê²Œì´ì§€ ì°¨íŠ¸ë¡œ ì‹œê°í™” (ê° ì ìˆ˜ê°€ 0ì—ì„œ 1 ì‚¬ì´ì„ì„ ê°€ì •)
        def create_gauge_chart(title, score):
            fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = score,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': f"<span style='font-size:1.2em'>{title}</span>"},
                gauge = {
                    'axis': {'range': [None, 1], 'tickwidth': 1, 'tickcolor': "darkblue"},
                    'bar': {'color': "darkblue"},
                    'bgcolor': "white",
                    'borderwidth': 2,
                    'bordercolor': "gray",
                    'steps': [
                        {'range': [0, 0.5], 'color': 'lightgray'},
                        {'range': [0.5, 0.75], 'color': 'lightblue'},
                        {'range': [0.75, 1], 'color': 'lightgreen'}],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': score}}))
            fig.update_layout(height=250, margin=dict(l=10, r=10, t=60, b=10))
            return fig

        col_metric1, col_metric2, col_metric3 = st.columns(3)

        with col_metric1:
            st.plotly_chart(create_gauge_chart("ì›¹ ê²€ìƒ‰ ë§¥ë½ ê´€ë ¨ì„±", evaluations['web_search_context_relevance_score']), use_container_width=True)

        with col_metric2:
            st.plotly_chart(create_gauge_chart("ì‘ë‹µ ê´€ë ¨ì„±", evaluations['response_relevancy_score']), use_container_width=True)

        with col_metric3:
            st.plotly_chart(create_gauge_chart("ì‘ë‹µ ê·¼ê±° ì ìˆ˜", evaluations['mean_response_groundedness_score']), use_container_width=True)

        st.markdown("---")

        # --- ì¶”ê°€ ì •ë³´ (ì„ íƒ ì‚¬í•­) ---
        st.info("ì´ ëŒ€ì‹œë³´ë“œëŠ” LLM ì—ì´ì „íŠ¸ì˜ ì£¼ìš” í‰ê°€ ì§€í‘œë¥¼ ì‹œê°í™”í•˜ì—¬ ì‹ ì†í•œ ì„±ëŠ¥ ë¶„ì„ì„ ë•ìŠµë‹ˆë‹¤.")
        st.caption("ë°ì´í„°ëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œ LLM í‰ê°€ ì‹œìŠ¤í…œì— ë”°ë¼ ë°ì´í„°ë¥¼ ì—°ë™í•´ì•¼ í•©ë‹ˆë‹¤.")


